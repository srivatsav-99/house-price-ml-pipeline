<<<<<<< HEAD
# House Price ML Pipeline (Linear â€¢ KNN â€¢ XGBoost)

**Author:** Srivatsav Shrikanth
**Goal:** Build a complete ML pipeline to predict home prices demonstrating how a classroom regression task can evolve into a business-ready analytical solution.

---

## Business Context

Real estate investors and analysts rely on accurate price estimation to benchmark listings, detect under or over-pricing, and guide purchase or renovation decisions. This project reframes an academic regression assignment into a **deployable, data driven pricing model** : bridging **business reasoning** with **technical precision**.

---

## Technical Workflow

1. **Data Source** - [Kaggle: King County Housing Data](https://www.kaggle.com/datasets/shivachandel/kc-house-data)
   (~21 000 rows, 21 features)
2. **Feature Engineering** - derive `house_age`, merge build/renovation years, log-transform target
3. **Preprocessing Pipeline** - `ColumnTransformer` + `Pipeline` for imputation, scaling, encoding
4. **Models** :

   * Linear Regression (baseline)
   * K-Nearest Neighbors (distance-weighted, target standardized)
   * XGBoost (ensemble with 500 trees, depth 6)
5. **Evaluation** â€“ R-squared Â· RMSE Â· MAE + residual diagnostics + feature importance visuals

---

## Results

| Model                     | R-squared  | RMSE         | MAE         |
| ------------------------- | ---------- | ------------ | ----------- |
| Linear Regression (Top-6) | 0.6408     | $248980     | $90485     |
| KNN Regression (K = 5)    | 0.7653     | $201 266     | $88467     |
| **XGBoost Regression**    | **0.8674** | **$151 278** | **$65343** |

> **+36 % performance gain** over the linear baseline by capturing nonlinear interactions and localized market effects.

---

## Key Visuals

|                                                       |                                                   |
| :---------------------------------------------------: | :-----------------------------------------------: |
| ![Feature Importance](outputs/feature_importance.png) | ![Residuals (XGBoost)](outputs/residuals_xgb.png) |

*(Figures exported from `MLAssignmentCorrected_files/` in repo as `outputs/`.)*

---

## Insights & Interpretation

* **Zip Code & sqft_above** dominate price variance; strong locational dependence.
* **Heteroscedasticity:** error variance increases with property value and model fits mid-range homes best.
* **Model trade-off:** Linear = interpretability / XGBoost = accuracy / KNN = local flexibility.
* Demonstrates understanding of both *statistical validity* and *business interpretability.*

---

## Tech Stack

Python Â· pandas Â· NumPy Â· scikit-learn Â· XGBoost Â· Matplotlib Â· os Â· kagglehub
Environment tested on Windows 11 Â· Python 3.12 (Anaconda)

---

## Project Layout

```
house-price-ml-pipeline/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ HousePrice_Pipeline.ipynb        â† full ML workflow
â”‚
â”œâ”€â”€ src/                                 â† modular scripts (future split)
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train_models.py
â”‚   â””â”€â”€ evaluate.py
â”‚
â”œâ”€â”€ outputs/                             â† residual & feature plots
â”œâ”€â”€ data/                                â† Kaggle dataset placeholder
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## What This Project Demonstrates

âœ… End-to-end ML workflow (business â†’ EDA â†’ model â†’ diagnostics)
âœ… Reproducible pipelines using scikit-learn best practices
âœ… Ability to interpret and communicate technical findings in business language
âœ… Mindset of an ML Engineer who bridges **academic analysis and production thinking**

---

## ğŸ¤ About the Author

**Srivatsav Shrikanth**
Graduate Student | Business Insights & Analytics (Humber College) Â· MSADA (Boston University MET)
=======
# House Price ML Pipeline (Linear â€¢ KNN â€¢ XGBoost)

**Author:** Srivatsav Shrikanth
**Goal:** Build a complete ML pipeline to predict home prices demonstrating how a classroom regression task can evolve into a business-ready analytical solution.

---

## Business Context

Real estate investors and analysts rely on accurate price estimation to benchmark listings, detect under or over-pricing, and guide purchase or renovation decisions. This project reframes an academic regression assignment into a **deployable, data driven pricing model** : bridging **business reasoning** with **technical precision**.

---

## Technical Workflow

1. **Data Source** - [Kaggle: King County Housing Data](https://www.kaggle.com/datasets/shivachandel/kc-house-data)
   (~21 000 rows, 21 features)
2. **Feature Engineering** - derive `house_age`, merge build/renovation years, log-transform target
3. **Preprocessing Pipeline** - `ColumnTransformer` + `Pipeline` for imputation, scaling, encoding
4. **Models** :

   * Linear Regression (baseline)
   * K-Nearest Neighbors (distance-weighted, target standardized)
   * XGBoost (ensemble with 500 trees, depth 6)
5. **Evaluation** â€“ R-squared Â· RMSE Â· MAE + residual diagnostics + feature importance visuals

---

## Results

| Model                     | R-squared  | RMSE         | MAE         |
| ------------------------- | ---------- | ------------ | ----------- |
| Linear Regression (Top-6) | 0.6408     | $248980     | $90485     |
| KNN Regression (K = 5)    | 0.7653     | $201 266     | $88467     |
| **XGBoost Regression**    | **0.8674** | **$151 278** | **$65343** |

> **+36 % performance gain** over the linear baseline by capturing nonlinear interactions and localized market effects.

---

## Key Visuals

|                                                       |                                                   |
| :---------------------------------------------------: | :-----------------------------------------------: |
| ![Feature Importance](outputs/feature_importance.png) | ![Residuals (XGBoost)](outputs/residuals_xgb.png) |

*(Figures exported from `MLAssignmentCorrected_files/` in repo as `outputs/`.)*

---

## Insights & Interpretation

* **Zip Code & sqft_above** dominate price variance; strong locational dependence.
* **Heteroscedasticity:** error variance increases with property value and model fits mid-range homes best.
* **Model trade-off:** Linear = interpretability / XGBoost = accuracy / KNN = local flexibility.
* Demonstrates understanding of both *statistical validity* and *business interpretability.*

---

## Tech Stack

Python Â· pandas Â· NumPy Â· scikit-learn Â· XGBoost Â· Matplotlib Â· os Â· kagglehub
Environment tested on Windows 11 Â· Python 3.12 (Anaconda)

---

## Project Layout

```
house-price-ml-pipeline/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ HousePrice_Pipeline.ipynb        â† full ML workflow
â”‚
â”œâ”€â”€ src/                                 â† modular scripts (future split)
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train_models.py
â”‚   â””â”€â”€ evaluate.py
â”‚
â”œâ”€â”€ outputs/                             â† residual & feature plots
â”œâ”€â”€ data/                                â† Kaggle dataset placeholder
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## What This Project Demonstrates

âœ… End-to-end ML workflow (business â†’ EDA â†’ model â†’ diagnostics)
âœ… Reproducible pipelines using scikit-learn best practices
âœ… Ability to interpret and communicate technical findings in business language
âœ… Mindset of an ML Engineer who bridges **academic analysis and production thinking**

---

## ğŸ¤ About the Author

**Srivatsav Shrikanth**
Graduate Student | Business Insights & Analytics (Humber College) Â· MSADA (Boston University MET)
>>>>>>> 03679f3 (Added structured pipeline, visuals, and professional README)
ğŸ“ Toronto, Canada